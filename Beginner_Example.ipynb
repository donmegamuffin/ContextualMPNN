{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Example usage\n",
        "\n",
        "Here, we'll just provide a few use-case examples of the codebase to get new users started.\n",
        "\n",
        "\n",
        "passing models."
      ],
      "metadata": {
        "id": "B0ROEFYL1sxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.activations import mish"
      ],
      "metadata": {
        "id": "z10RpvKP2M4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Crystal graph construction\n",
        "\n",
        "To start, we'll just demonstrate the method for creating crystal graphs suitable for input into contextual message. We'll assume for now, we're working with the materials project 2018 mp.2018.6.1.json file that was provided at https://paperswithcode.com/dataset/materials-project."
      ],
      "metadata": {
        "id": "NE7IUb5L1tpr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R13cJiGqvJE7"
      },
      "outputs": [],
      "source": [
        "# Load the json into memory\n",
        "with open(r\"mp.2018.6.1.json\",'r') as f:\n",
        "  json_data = json.load(f)\n",
        "\n",
        "# To make things easier, we'll perform this crystal graph construction\n",
        "# for just the first entry.\n",
        "# First parse the structure cif string and the target property\n",
        "structure_string = json_data[0][\"structure\"]                  # our \"X\"\n",
        "target_property  = json_data[0][\"formation_energy_per_atom\"]  # our \"y\"\n",
        "\n",
        "# We provide a preconstructed function in the data_input.graphs for\n",
        "# converting a structure string to a graph, so we'll use that here.\n",
        "# For construction customization, we'd recommend looking at the\n",
        "# source code for mp_s2dgknn. Here, by default, it'll create a\n",
        "# 48-KNN edge multiplex graph with both real and reciprocal-space\n",
        "# edges.\n",
        "from ContextualMPNN.data_input.graphs import mp_s2dgknn\n",
        "structure_graph = mp_s2dgknn(structure_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using this across the whole dataset, a dataset of graph-target pairs can be generated assuming original data is provided in cif format. The underlying code converts the cif strings to pymatgen Structures, so if cif files cannot be used, pymatgen structures are the next-best option."
      ],
      "metadata": {
        "id": "STGkQB4D5ukk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model creation\n",
        "\n",
        "Model creation should also be a relatively simple affair as we provide a method for construction of the architecture used during research. The only things necessary are the construction parameters. Here, we'll make a relatively small contextual model with a relatively coarse edge expansion. This can be configured and experimented with to tailor to individual tastes."
      ],
      "metadata": {
        "id": "ISRKx4yA7A_8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ContextualMPNN.model.contextual import make_context_model\n",
        "\n",
        "# Set the edge expansion parameters\n",
        "gaussian_centers\t= np.linspace(0.,5.,100)\n",
        "gaussian_width\t  = 0.25\n",
        "layer_width       = 64\n",
        "\n",
        "# batch up the parameters, and create the model\n",
        "params = {\"centers\" : gaussian_centers,\n",
        "          \"width\"   : gaussian_width,\n",
        "          \"C\"       : layer_width}\n",
        "model = make_context_model(**params)\n",
        "\n",
        "# Now, we'll simply compile it using standard keras.\n",
        "model.compile(\"adam\",\"mse\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "1t3rbCH98C-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "Here, we'll assume we're training a contextual MPNN with support for reciprocal space features, and provide a code snippet to demonstrate how you might go about doing that."
      ],
      "metadata": {
        "id": "MrwduGQC99fp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we need to flatten our graph dataset we have.\n",
        "# As this example we will assume dual graphs and a dataset of more than one\n",
        "# graph, then we will import and use the appropriate function\n",
        "from ContextualMPNN.graphs import flatten_dual_dataset\n",
        "X = flatten_dual_dataset(graphs)\n",
        "y = np.array(target_property).reshape(-1,1) # Assume single target\n",
        "\n",
        "# Now we import and create the batch generator keras will use to draw samples\n",
        "from ContextualMPNN.data_input.batch_generators import DualGraphBatchGenerator\n",
        "data_generator = DualGraphBatchGenerator(*X, targets = y, batch_size=64)\n",
        "\n",
        "# Now we simply call model.fit() as we would with any other keras model!\n",
        "# Due to the DualGraphBatchGenerator implicity pre-batching our graphs,\n",
        "# it is best we use batch_size=1 to prevent too much memory usage\n",
        "model.fit(data_generator,\n",
        "          steps_per_epoch=len(train_generator),\n",
        "          epochs=10,\n",
        "          batch_size=1)"
      ],
      "metadata": {
        "id": "hP-NhCP592c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we've provided the very fundamental useage cases of the model and framework. In practice, individual projects well require much more tweaking and robust training, and data preparation schemes. Likewise, we haven't covered model creation, but for further details there, it's recommended to look at the source for the `make_context_model(...)` source code."
      ],
      "metadata": {
        "id": "Uy8PHPo_Bfsn"
      }
    }
  ]
}